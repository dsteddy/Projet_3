{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "link = 'datasets/WTTJ_offers.csv'\n",
    "\n",
    "df_wttj = pd.read_csv(link)\n",
    "\n",
    "link = 'datasets/pole_emploi_offers.csv'\n",
    "\n",
    "df_pole_emploi = pd.read_csv(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>intitule</th>\n",
       "      <th>description</th>\n",
       "      <th>date_publication</th>\n",
       "      <th>date_modif</th>\n",
       "      <th>contrat</th>\n",
       "      <th>competences</th>\n",
       "      <th>duree_travail</th>\n",
       "      <th>type_contrat</th>\n",
       "      <th>secteur_activite</th>\n",
       "      <th>agence</th>\n",
       "      <th>niveau_etudes</th>\n",
       "      <th>salaire</th>\n",
       "      <th>entreprise</th>\n",
       "      <th>description_entreprise</th>\n",
       "      <th>ville</th>\n",
       "      <th>code_postal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Analyst (H/F)</td>\n",
       "      <td>À propos de SkillsFirst :\\n\\nSkillsFirst accom...</td>\n",
       "      <td>2024-01-05 15:43:43+00:00</td>\n",
       "      <td>2024-01-08 15:50:02+00:00</td>\n",
       "      <td>CDI</td>\n",
       "      <td>[{'code': '109527', 'libelle': 'Adapter les ou...</td>\n",
       "      <td>35H Travail en journée</td>\n",
       "      <td>Temps plein</td>\n",
       "      <td>Formation continue d'adultes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Annuel de 42000,00 Euros à 48000,00 Euros sur ...</td>\n",
       "      <td>EDUGROUPE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75 - PARIS 16</td>\n",
       "      <td>75016.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data analyst</td>\n",
       "      <td>Tu souhaites une aventure humaine et challenge...</td>\n",
       "      <td>2024-01-05 09:23:05+00:00</td>\n",
       "      <td>2024-01-08 12:50:51+00:00</td>\n",
       "      <td>CDI</td>\n",
       "      <td>[{'code': '109527', 'libelle': 'Adapter les ou...</td>\n",
       "      <td>39H Travail en journée</td>\n",
       "      <td>Temps plein</td>\n",
       "      <td>Ingénierie, études techniques</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Annuel de 30000,00 Euros sur 12 mois</td>\n",
       "      <td>FORTIL NORD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59 - VILLENEUVE D ASCQ</td>\n",
       "      <td>59491.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data analyst</td>\n",
       "      <td>Nous sommes une entreprise de services numériq...</td>\n",
       "      <td>2024-01-04 12:29:52+00:00</td>\n",
       "      <td>2024-01-08 16:02:26+00:00</td>\n",
       "      <td>CDI</td>\n",
       "      <td>[{'code': '109527', 'libelle': 'Adapter les ou...</td>\n",
       "      <td>35H Travail en journée</td>\n",
       "      <td>Temps plein</td>\n",
       "      <td>Conseil en systèmes et logiciels informatiques</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>VIRTUAL CONSULTING</td>\n",
       "      <td>Virtual consulting est une société spécialisé ...</td>\n",
       "      <td>59 - LILLE</td>\n",
       "      <td>59000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DATA BUSINESS ANALYST (H/F)</td>\n",
       "      <td>Vous êtes un(e) Data Business Analyst confirmé...</td>\n",
       "      <td>2024-01-04 10:30:01+00:00</td>\n",
       "      <td>2024-01-05 20:16:11+00:00</td>\n",
       "      <td>CDI</td>\n",
       "      <td>[{'code': '109527', 'libelle': 'Adapter les ou...</td>\n",
       "      <td>37H30 Travail en journée</td>\n",
       "      <td>Temps plein</td>\n",
       "      <td>Programmation informatique</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bac+5 et plus ou équivalents</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HARDIS GROUPE</td>\n",
       "      <td>\"Hardis Group est une ESN, une entreprise de c...</td>\n",
       "      <td>38 - GRENOBLE</td>\n",
       "      <td>38000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data analyst F/H (H/F)</td>\n",
       "      <td>Airbus SAS, leader mondial de l'industrie aéro...</td>\n",
       "      <td>2024-01-04 09:41:23+00:00</td>\n",
       "      <td>2024-01-05 11:49:07+00:00</td>\n",
       "      <td>MIS</td>\n",
       "      <td>[{'code': '109527', 'libelle': 'Adapter les ou...</td>\n",
       "      <td>35H Travail en journée</td>\n",
       "      <td>Temps plein</td>\n",
       "      <td>Activités des agences de travail temporaire</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Annuel de 35000,00 Euros à 40000,00 Euros sur ...</td>\n",
       "      <td>Synergie</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31 - BLAGNAC</td>\n",
       "      <td>31700.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      intitule  \\\n",
       "0           Data Analyst (H/F)   \n",
       "1                 Data analyst   \n",
       "2                 Data analyst   \n",
       "3  DATA BUSINESS ANALYST (H/F)   \n",
       "4       Data analyst F/H (H/F)   \n",
       "\n",
       "                                         description  \\\n",
       "0  À propos de SkillsFirst :\\n\\nSkillsFirst accom...   \n",
       "1  Tu souhaites une aventure humaine et challenge...   \n",
       "2  Nous sommes une entreprise de services numériq...   \n",
       "3  Vous êtes un(e) Data Business Analyst confirmé...   \n",
       "4  Airbus SAS, leader mondial de l'industrie aéro...   \n",
       "\n",
       "            date_publication                 date_modif contrat  \\\n",
       "0  2024-01-05 15:43:43+00:00  2024-01-08 15:50:02+00:00     CDI   \n",
       "1  2024-01-05 09:23:05+00:00  2024-01-08 12:50:51+00:00     CDI   \n",
       "2  2024-01-04 12:29:52+00:00  2024-01-08 16:02:26+00:00     CDI   \n",
       "3  2024-01-04 10:30:01+00:00  2024-01-05 20:16:11+00:00     CDI   \n",
       "4  2024-01-04 09:41:23+00:00  2024-01-05 11:49:07+00:00     MIS   \n",
       "\n",
       "                                         competences  \\\n",
       "0  [{'code': '109527', 'libelle': 'Adapter les ou...   \n",
       "1  [{'code': '109527', 'libelle': 'Adapter les ou...   \n",
       "2  [{'code': '109527', 'libelle': 'Adapter les ou...   \n",
       "3  [{'code': '109527', 'libelle': 'Adapter les ou...   \n",
       "4  [{'code': '109527', 'libelle': 'Adapter les ou...   \n",
       "\n",
       "              duree_travail type_contrat  \\\n",
       "0    35H Travail en journée  Temps plein   \n",
       "1    39H Travail en journée  Temps plein   \n",
       "2    35H Travail en journée  Temps plein   \n",
       "3  37H30 Travail en journée  Temps plein   \n",
       "4    35H Travail en journée  Temps plein   \n",
       "\n",
       "                                 secteur_activite agence  \\\n",
       "0                    Formation continue d'adultes    NaN   \n",
       "1                   Ingénierie, études techniques    NaN   \n",
       "2  Conseil en systèmes et logiciels informatiques    NaN   \n",
       "3                      Programmation informatique    NaN   \n",
       "4     Activités des agences de travail temporaire    NaN   \n",
       "\n",
       "                  niveau_etudes  \\\n",
       "0                           NaN   \n",
       "1                           NaN   \n",
       "2                           NaN   \n",
       "3  Bac+5 et plus ou équivalents   \n",
       "4                           NaN   \n",
       "\n",
       "                                             salaire          entreprise  \\\n",
       "0  Annuel de 42000,00 Euros à 48000,00 Euros sur ...           EDUGROUPE   \n",
       "1               Annuel de 30000,00 Euros sur 12 mois         FORTIL NORD   \n",
       "2                                                NaN  VIRTUAL CONSULTING   \n",
       "3                                                NaN       HARDIS GROUPE   \n",
       "4  Annuel de 35000,00 Euros à 40000,00 Euros sur ...            Synergie   \n",
       "\n",
       "                              description_entreprise                   ville  \\\n",
       "0                                                NaN           75 - PARIS 16   \n",
       "1                                                NaN  59 - VILLENEUVE D ASCQ   \n",
       "2  Virtual consulting est une société spécialisé ...              59 - LILLE   \n",
       "3  \"Hardis Group est une ESN, une entreprise de c...           38 - GRENOBLE   \n",
       "4                                                NaN            31 - BLAGNAC   \n",
       "\n",
       "   code_postal  \n",
       "0      75016.0  \n",
       "1      59491.0  \n",
       "2      59000.0  \n",
       "3      38000.0  \n",
       "4      31700.0  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pole_emploi.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type_contrat</th>\n",
       "      <th>niveau_etudes</th>\n",
       "      <th>intitule</th>\n",
       "      <th>date_publication</th>\n",
       "      <th>description</th>\n",
       "      <th>contract_duration_min</th>\n",
       "      <th>salary_period</th>\n",
       "      <th>salary_min</th>\n",
       "      <th>experience</th>\n",
       "      <th>date_modif</th>\n",
       "      <th>salary_max</th>\n",
       "      <th>ville</th>\n",
       "      <th>code_postal</th>\n",
       "      <th>description_entreprise</th>\n",
       "      <th>secteur_activite</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>internship</td>\n",
       "      <td>bac_5</td>\n",
       "      <td>Data Analyst - Climate Expert - Internship</td>\n",
       "      <td>2024-01-08T14:46:02Z</td>\n",
       "      <td>At Greenly, we are on a mission to lead the wa...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LESS_THAN_6_MONTHS</td>\n",
       "      <td>2024-01-08T14:46:03Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Paris</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Founded in 2019 by Alexis, Matthieu and Arnaud...</td>\n",
       "      <td>SocialTech / GreenTech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>full_time</td>\n",
       "      <td>bac_5</td>\n",
       "      <td>CDI - Product data analyst - H/F</td>\n",
       "      <td>2024-01-08T14:20:22Z</td>\n",
       "      <td>Votre rôle au sein de l’équipe Au sein du serv...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LESS_THAN_6_MONTHS</td>\n",
       "      <td>2024-01-08T14:20:23Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Boulogne-Billancourt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TF1 Group is global player in content, present...</td>\n",
       "      <td>Media, Advertising, AdTech / MarTech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>full_time</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Consultant Expérimenté &amp; Manager en « Data Ana...</td>\n",
       "      <td>2024-01-08T14:04:50Z</td>\n",
       "      <td>L’opportunité En travaillant dans une équipe e...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-01-08T14:04:52Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Paris</td>\n",
       "      <td>NaN</td>\n",
       "      <td>“Building a better working world” Aider les pi...</td>\n",
       "      <td>Strategy, Audit, Transaction Services, Digital...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>internship</td>\n",
       "      <td>bac_5</td>\n",
       "      <td>Data engineer/analyst (stage) H/F</td>\n",
       "      <td>2024-01-08T14:35:47Z</td>\n",
       "      <td>Tu cherches à donner du sens à ton talent et à...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-01-08T14:35:48Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Paris</td>\n",
       "      <td>NaN</td>\n",
       "      <td>En 2016, Julie, Nicolas, Cédric, Lionel et Fre...</td>\n",
       "      <td>Software, SaaS / Cloud Services, Health</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>internship</td>\n",
       "      <td>bac_5</td>\n",
       "      <td>Stage Data Analyst</td>\n",
       "      <td>2024-01-08T14:04:56Z</td>\n",
       "      <td>Ta mission si tu l’acceptes : Au sein de notre...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>monthly</td>\n",
       "      <td>750.0</td>\n",
       "      <td>LESS_THAN_6_MONTHS</td>\n",
       "      <td>2024-01-08T14:04:57Z</td>\n",
       "      <td>800.0</td>\n",
       "      <td>Paris</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Lulu dans ma rue réinvente la conciergerie de ...</td>\n",
       "      <td>Collaborative Economy, Home Care Services, Cor...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  type_contrat niveau_etudes  \\\n",
       "0   internship         bac_5   \n",
       "1    full_time         bac_5   \n",
       "2    full_time           NaN   \n",
       "3   internship         bac_5   \n",
       "4   internship         bac_5   \n",
       "\n",
       "                                            intitule      date_publication  \\\n",
       "0        Data Analyst - Climate Expert - Internship   2024-01-08T14:46:02Z   \n",
       "1                   CDI - Product data analyst - H/F  2024-01-08T14:20:22Z   \n",
       "2  Consultant Expérimenté & Manager en « Data Ana...  2024-01-08T14:04:50Z   \n",
       "3                  Data engineer/analyst (stage) H/F  2024-01-08T14:35:47Z   \n",
       "4                                 Stage Data Analyst  2024-01-08T14:04:56Z   \n",
       "\n",
       "                                         description  contract_duration_min  \\\n",
       "0  At Greenly, we are on a mission to lead the wa...                    4.0   \n",
       "1  Votre rôle au sein de l’équipe Au sein du serv...                    NaN   \n",
       "2  L’opportunité En travaillant dans une équipe e...                    NaN   \n",
       "3  Tu cherches à donner du sens à ton talent et à...                    5.0   \n",
       "4  Ta mission si tu l’acceptes : Au sein de notre...                    5.0   \n",
       "\n",
       "  salary_period  salary_min          experience            date_modif  \\\n",
       "0           NaN         NaN  LESS_THAN_6_MONTHS  2024-01-08T14:46:03Z   \n",
       "1           NaN         NaN  LESS_THAN_6_MONTHS  2024-01-08T14:20:23Z   \n",
       "2           NaN         NaN                 NaN  2024-01-08T14:04:52Z   \n",
       "3           NaN         NaN                 NaN  2024-01-08T14:35:48Z   \n",
       "4       monthly       750.0  LESS_THAN_6_MONTHS  2024-01-08T14:04:57Z   \n",
       "\n",
       "   salary_max                 ville  code_postal  \\\n",
       "0         NaN                 Paris          NaN   \n",
       "1         NaN  Boulogne-Billancourt          NaN   \n",
       "2         NaN                 Paris          NaN   \n",
       "3         NaN                 Paris          NaN   \n",
       "4       800.0                 Paris          NaN   \n",
       "\n",
       "                              description_entreprise  \\\n",
       "0  Founded in 2019 by Alexis, Matthieu and Arnaud...   \n",
       "1  TF1 Group is global player in content, present...   \n",
       "2  “Building a better working world” Aider les pi...   \n",
       "3  En 2016, Julie, Nicolas, Cédric, Lionel et Fre...   \n",
       "4  Lulu dans ma rue réinvente la conciergerie de ...   \n",
       "\n",
       "                                    secteur_activite  \n",
       "0                             SocialTech / GreenTech  \n",
       "1               Media, Advertising, AdTech / MarTech  \n",
       "2  Strategy, Audit, Transaction Services, Digital...  \n",
       "3            Software, SaaS / Cloud Services, Health  \n",
       "4  Collaborative Economy, Home Care Services, Cor...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_wttj.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Votre rôle au sein de l’équipe Au sein du service « Pilotage de la performance et de la recommandation » (MYTF1, TFOU, TF1 Info, Max), qui reunit des business analyst, des data analysts, et des chargés de datavisualisation, vous serez en charge de l'analyse, de l'évaluation et de la modélisation de la recommandation sur les offres digitales de TF1. Vos missions seront : D'analyser les comportements des utilisateurs sur les plateformes digitales de TF1, et de définir les opportunités de recommandation (fonctionnalités, contenus, expériences) ; D'évaluer les recommandations proposées sur TF1 et les optimiser (algorithmes, stock, conversion) ; De définir la méthodologie de recommandation adaptée (user, content, cohort, personnalisation…) ; De proposer de nouvelles manières de segmenter nos audiences pour optimiser les recommandations, et définissez les spec pour les data ingénieurs ; D'être force de proposition quant à la recommandation, à travers une veille permanente des acteurs streaming et vidéo, et de la compréhension des comportements des internautes ; De participer à l'amélioration des méthodologies adoptées et des métadonnées utilisées ; D’être un interlocuteur privilégié entre le service data/tech et les équipes métier eTF1 (éditorial, produit…).\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_wttj.description.iloc[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tests lanchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import \n",
    "llm = OpenAI(model_name=\"text-davinci-003\")\n",
    "llm(\"explain large language models in one sentence\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "\n",
    "template = \"\"\"\n",
    "blabla {job_offer}\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"job_offer\"],\n",
    "    template=template\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain\n",
    "chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "print(chain.run(\"autoencoder\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_prompt = PromptTemplate(\n",
    "    input_variables=[\"ml_concept\"],\n",
    "    template = \"Turn the concept description of {ml_concept} and explain it to me like I'm five\",\n",
    ")\n",
    "chain_two = LLMChain(llm=llm, prompt=second_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SimpleSequentialChain\n",
    "overall_chain = SimpleSequentialChain(chains=[chain, chain_two], verbose=True)\n",
    "\n",
    "explanation = overall_chain.run(\"autoencoder\")\n",
    "print(explanation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# falcon7b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\royde\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\huggingface_hub\\utils\\_deprecation.py:127: FutureWarning: '__init__' (from 'huggingface_hub.inference_api') is deprecated and will be removed from version '1.0'. `InferenceApi` client is deprecated in favor of the more feature-complete `InferenceClient`. Check out this guide to learn how to convert your script to use it: https://huggingface.co/docs/huggingface_hub/guides/inference#legacy-inferenceapi-client.\n",
      "  warnings.warn(warning_message, FutureWarning)\n"
     ]
    },
    {
     "ename": "GatedRepoError",
     "evalue": "403 Client Error. (Request ID: Root=1-659c1748-1f6aebee599f27942fe52b1b;efa99b37-8b03-4a56-bfe9-3f07e9cd5973)\n\nCannot access gated repo for url https://huggingface.co/api/models/meta-llama/Llama-2-7b-chat-hf.\nAccess to model meta-llama/Llama-2-7b-chat-hf is restricted and you are not in the authorized list. Visit https://huggingface.co/meta-llama/Llama-2-7b-chat-hf to ask for access.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\royde\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\huggingface_hub\\utils\\_errors.py:270\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[1;34m(response, endpoint_name)\u001b[0m\n\u001b[0;32m    269\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 270\u001b[0m     \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    271\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\royde\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\requests\\models.py:1021\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1020\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[1;32m-> 1021\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[1;31mHTTPError\u001b[0m: 403 Client Error: Forbidden for url: https://huggingface.co/api/models/meta-llama/Llama-2-7b-chat-hf",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mGatedRepoError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HuggingFaceHub\n\u001b[0;32m      5\u001b[0m repo_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmeta-llama/Llama-2-7b-chat-hf\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 6\u001b[0m llm \u001b[38;5;241m=\u001b[39m \u001b[43mHuggingFaceHub\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhuggingfacehub_api_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhuggingfacehub_api_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m0.6\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_new_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\royde\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain_core\\load\\serializable.py:97\u001b[0m, in \u001b[0;36mSerializable.__init__\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 97\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     98\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lc_kwargs \u001b[38;5;241m=\u001b[39m kwargs\n",
      "File \u001b[1;32mc:\\Users\\royde\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pydantic\\v1\\main.py:339\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[1;34m(__pydantic_self__, **data)\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;124;03mCreate a new model by parsing and validating input data from keyword arguments.\u001b[39;00m\n\u001b[0;32m    335\u001b[0m \n\u001b[0;32m    336\u001b[0m \u001b[38;5;124;03mRaises ValidationError if the input data cannot be parsed to form a valid model.\u001b[39;00m\n\u001b[0;32m    337\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    338\u001b[0m \u001b[38;5;66;03m# Uses something other than `self` the first arg to allow \"self\" as a settable attribute\u001b[39;00m\n\u001b[1;32m--> 339\u001b[0m values, fields_set, validation_error \u001b[38;5;241m=\u001b[39m \u001b[43mvalidate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m__pydantic_self__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__class__\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    340\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m validation_error:\n\u001b[0;32m    341\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m validation_error\n",
      "File \u001b[1;32mc:\\Users\\royde\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pydantic\\v1\\main.py:1102\u001b[0m, in \u001b[0;36mvalidate_model\u001b[1;34m(model, input_data, cls)\u001b[0m\n\u001b[0;32m   1100\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   1101\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1102\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[43mvalidator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcls_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1103\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mAssertionError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m   1104\u001b[0m     errors\u001b[38;5;241m.\u001b[39mappend(ErrorWrapper(exc, loc\u001b[38;5;241m=\u001b[39mROOT_KEY))\n",
      "File \u001b[1;32mc:\\Users\\royde\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain\\llms\\huggingface_hub.py:56\u001b[0m, in \u001b[0;36mHuggingFaceHub.validate_environment\u001b[1;34m(cls, values)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhuggingface_hub\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minference_api\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m InferenceApi\n\u001b[0;32m     55\u001b[0m repo_id \u001b[38;5;241m=\u001b[39m values[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrepo_id\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m---> 56\u001b[0m client \u001b[38;5;241m=\u001b[39m \u001b[43mInferenceApi\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     57\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     58\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhuggingfacehub_api_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     59\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtask\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     60\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m client\u001b[38;5;241m.\u001b[39mtask \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m VALID_TASKS:\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     63\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGot invalid task \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclient\u001b[38;5;241m.\u001b[39mtask\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     64\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcurrently only \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mVALID_TASKS\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m are supported\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     65\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\royde\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\huggingface_hub\\utils\\_validators.py:118\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[0;32m    116\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m--> 118\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\royde\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\huggingface_hub\\utils\\_deprecation.py:128\u001b[0m, in \u001b[0;36m_deprecate_method.<locals>._inner_deprecate_method.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    126\u001b[0m     warning_message \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m message\n\u001b[0;32m    127\u001b[0m warnings\u001b[38;5;241m.\u001b[39mwarn(warning_message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m)\n\u001b[1;32m--> 128\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\royde\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\huggingface_hub\\inference_api.py:131\u001b[0m, in \u001b[0;36mInferenceApi.__init__\u001b[1;34m(self, repo_id, task, token, gpu)\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mheaders \u001b[38;5;241m=\u001b[39m build_hf_headers(token\u001b[38;5;241m=\u001b[39mtoken)\n\u001b[0;32m    130\u001b[0m \u001b[38;5;66;03m# Configure task\u001b[39;00m\n\u001b[1;32m--> 131\u001b[0m model_info \u001b[38;5;241m=\u001b[39m \u001b[43mHfApi\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m model_info\u001b[38;5;241m.\u001b[39mpipeline_tag \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m task:\n\u001b[0;32m    133\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    134\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTask not specified in the repository. Please add it to the model card\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    135\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m using pipeline_tag\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    136\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m (https://huggingface.co/docs#how-is-a-models-type-of-inference-api-and-widget-determined)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    137\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\royde\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\huggingface_hub\\utils\\_validators.py:118\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[0;32m    116\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m--> 118\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\royde\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\huggingface_hub\\hf_api.py:1922\u001b[0m, in \u001b[0;36mHfApi.model_info\u001b[1;34m(self, repo_id, revision, timeout, securityStatus, files_metadata, token)\u001b[0m\n\u001b[0;32m   1920\u001b[0m     params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mblobs\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1921\u001b[0m r \u001b[38;5;241m=\u001b[39m get_session()\u001b[38;5;241m.\u001b[39mget(path, headers\u001b[38;5;241m=\u001b[39mheaders, timeout\u001b[38;5;241m=\u001b[39mtimeout, params\u001b[38;5;241m=\u001b[39mparams)\n\u001b[1;32m-> 1922\u001b[0m \u001b[43mhf_raise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43mr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1923\u001b[0m data \u001b[38;5;241m=\u001b[39m r\u001b[38;5;241m.\u001b[39mjson()\n\u001b[0;32m   1924\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ModelInfo(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdata)\n",
      "File \u001b[1;32mc:\\Users\\royde\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\huggingface_hub\\utils\\_errors.py:286\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[1;34m(response, endpoint_name)\u001b[0m\n\u001b[0;32m    282\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m error_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGatedRepo\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    283\u001b[0m     message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    284\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Client Error.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot access gated repo for url \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    285\u001b[0m     )\n\u001b[1;32m--> 286\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m GatedRepoError(message, response) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    288\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m (\n\u001b[0;32m    289\u001b[0m     response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m401\u001b[39m\n\u001b[0;32m    290\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m response\u001b[38;5;241m.\u001b[39mrequest\u001b[38;5;241m.\u001b[39murl \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    293\u001b[0m     \u001b[38;5;66;03m# Collection not found. We don't raise a custom error for this.\u001b[39;00m\n\u001b[0;32m    294\u001b[0m     \u001b[38;5;66;03m# This prevent from raising a misleading `RepositoryNotFoundError` (see below).\u001b[39;00m\n\u001b[0;32m    295\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "\u001b[1;31mGatedRepoError\u001b[0m: 403 Client Error. (Request ID: Root=1-659c1748-1f6aebee599f27942fe52b1b;efa99b37-8b03-4a56-bfe9-3f07e9cd5973)\n\nCannot access gated repo for url https://huggingface.co/api/models/meta-llama/Llama-2-7b-chat-hf.\nAccess to model meta-llama/Llama-2-7b-chat-hf is restricted and you are not in the authorized list. Visit https://huggingface.co/meta-llama/Llama-2-7b-chat-hf to ask for access."
     ]
    }
   ],
   "source": [
    "huggingfacehub_api_token=\"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\"\n",
    "\n",
    "from langchain import HuggingFaceHub\n",
    "\n",
    "repo_id = \"meta-llama/Llama-2-7b-chat-hf\"\n",
    "llm = HuggingFaceHub(huggingfacehub_api_token=huggingfacehub_api_token,\n",
    "                     repo_id=repo_id,\n",
    "                     model_kwargs={\"temperature\":0.6, \"max_new_tokens\":500})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate, LLMChain\n",
    "\n",
    "template = \"\"\"\n",
    "Tu es un spécialiste en recrutement et offre d'emplois.\n",
    "Tu vas aider l'utilisateur a ressortir les informations demandées dans une offre d'emploi fournie.\n",
    "\n",
    "Tu vas fournir tes réponses sous formes de liste suivant cet exemple :\n",
    "\"Compétences techniques :\n",
    "-Power BI\n",
    "-Tableau\n",
    "-etc...\n",
    "\"\n",
    "\n",
    "Voici la demande :\n",
    "{question}\n",
    "\"\"\"\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"question\"])\n",
    "llm_chain = LLMChain(prompt=prompt, llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "La personne recherchée devra répondre à cette demande en utilisant des données techniques pour les spécifications de l'offre d'emploi.\n",
      "La personne recherchée devra comprendre les détails techniques de l'offre d'emploi et les appliquer à de l'exemple d'offre d'emploi. La personne recherchée devra aussi avoir des connaissances en data science et en intelligence artificielle pour pouvoir analyser les données.\n"
     ]
    }
   ],
   "source": [
    "question = \"\"\"\n",
    "Quelles sont les soft skill dans cette offre :\n",
    "\n",
    "\"Votre rôle au sein de l’équipe Au sein du service « Pilotage de la performance et de la recommandation »\n",
    "(MYTF1, TFOU, TF1 Info, Max), qui reunit des business analyst, des data analysts, et des chargés de datavisualisation,\n",
    "vous serez en charge de l'analyse, de l'évaluation et de la modélisation de la recommandation sur les offres digitales de TF1.\n",
    "Vos missions seront : D'analyser les comportements des utilisateurs sur les plateformes digitales de TF1,\n",
    "et de définir les opportunités de recommandation (fonctionnalités, contenus, expériences) ;\n",
    "D'évaluer les recommandations proposées sur TF1 et les optimiser (algorithmes, stock, conversion) ;\n",
    "De définir la méthodologie de recommandation adaptée (user, content, cohort, personnalisation…) ;\n",
    "De proposer de nouvelles manières de segmenter nos audiences pour optimiser les recommandations, et définissez les spec pour les data ingénieurs ;\n",
    "D'être force de proposition quant à la recommandation, à travers une veille permanente des acteurs streaming et vidéo, et de la compréhension des comportements des internautes ;\n",
    "De participer à l'amélioration des méthodologies adoptées et des métadonnées utilisées ;\n",
    "D’être un interlocuteur privilégié entre le service data/tech et les équipes métier eTF1 (éditorial, produit…).\"\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "print(llm_chain.run(question))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
