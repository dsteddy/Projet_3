{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import re\n",
    "import requests\n",
    "import pandas as pd\n",
    "import asyncio\n",
    "import aiohttp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def job_offers_wtj(\n",
    "        job_title: str = \"data analyst\",\n",
    "        pages: int = 1\n",
    "):\n",
    "    \"\"\"\n",
    "    ---\n",
    "    Web scraping WTJ\n",
    "    ---\n",
    "    Lance un navigateur et créée un dataframe contenant les informations de\n",
    "    chaque offre d'emploi pour un nombre de pages définis sur le site\n",
    "    Welcome To The Jungle.\n",
    "    ---\n",
    "    Paramètres :\n",
    "    - job_title: str : Le nom du métier pour lequel rechercher des offres.\n",
    "    - pages: int : Le nombre de pages sur lesquels rechercher les offres.\n",
    "    ---\n",
    "    Retourne :\n",
    "    - Le df contenant les informations de toute les offres récupérées.\n",
    "    \"\"\"\n",
    "    # Instanciation de la liste contenant les liens pour les requêtes APIs.\n",
    "    api_links = []\n",
    "    # Lien de l'API de Welcome To The Jungle pour récupérer les données.\n",
    "    api_link = f\"https://api.welcometothejungle.com/api/v1/organizations\"\n",
    "    job = job_title.lower().replace(\" \", \"+\")\n",
    "    # Instanciation du driver Firefox.\n",
    "    driver = webdriver.Firefox()\n",
    "    # Instanciation du dataframe final.\n",
    "    full_df = pd.DataFrame()\n",
    "    # Nom des colonnes à garder dans le dataframe final.\n",
    "    cols_to_keep = [\n",
    "        \"name\",\n",
    "        \"salary_period\",\n",
    "        \"experience_level\",\n",
    "        \"apply_url\",\n",
    "        \"contract_duration_min\",\n",
    "        \"office.city\",\n",
    "        \"office.address\",\n",
    "        \"office.district\",\n",
    "        \"office.latitude\",\n",
    "        \"office.longitude\",\n",
    "        \"office.zip_code\",\n",
    "        \"profession.category.fr\",\n",
    "        \"profession.name.fr\"\n",
    "        \"name\",\n",
    "        \"education_level\",\n",
    "        \"application_fields.mode\",\n",
    "        \"application_fields.name\",\n",
    "        \"description\",\n",
    "        \"organization.average_age\",\n",
    "        \"organization.creation_year\",\n",
    "        \"organization.default_language\",\n",
    "        \"organization.description\",\n",
    "        \"organization.industry\",\n",
    "        \"organization.nb_employee\",\n",
    "        \"contract_type\",\n",
    "        \"salary_min\",\n",
    "        \"salary_max\",\n",
    "        \"education_level\",\n",
    "        \"remote\"\n",
    "    ]\n",
    "    try:\n",
    "        for i in range(1, pages+1):\n",
    "            url = f\"https://www.welcometothejungle.com/fr/jobs?refinementList%5Boffices.country_code%5D%5B%5D=FR&query={job}&page={i}\"\n",
    "            # Ouvre chaque page sur le navigateur.\n",
    "            driver.get(url)\n",
    "            try:\n",
    "                # Récupère le lien de chaque offre d'emploi sur la page.\n",
    "                contents = WebDriverWait(driver, 20).until(\n",
    "                    EC.presence_of_all_elements_located((By.CSS_SELECTOR, \".sc-6i2fyx-0.gIvJqh\"))\n",
    "                )\n",
    "                for content in contents:\n",
    "                    link = content.get_attribute(\"href\")\n",
    "                    end_link = re.findall(r\"/companies(.+)\", link)[0]\n",
    "                    full_link = api_link + end_link\n",
    "                    # Rajoute le lien de chaque offre à la liste.\n",
    "                    api_links.append(full_link)\n",
    "            except Exception as e:\n",
    "                print(f\"Error scraping page {i} : {e}\")\n",
    "    finally:\n",
    "        driver.quit()\n",
    "    # Pour chaque lien de la liste, fait une requête API et stocke les informations dans un dataframe.\n",
    "    for link_ in api_links:\n",
    "        r = requests.get(link_)\n",
    "        df = pd.json_normalize(\n",
    "            r.json()[\"job\"]\n",
    "        )\n",
    "        full_df = pd.concat([full_df, df], ignore_index=True)\n",
    "    # Instanciation de la liste des colonnes à drop.\n",
    "    cols_to_drop = [col for col in full_df.columns if col not in cols_to_keep]\n",
    "    df = full_df.drop(columns=cols_to_drop)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = job_offers_wtj(\"data analyst\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "def clean_html(text):\n",
    "    soup = BeautifulSoup(text, \"html.parser\")\n",
    "    cleaned_text = soup.get_text(separator=\" \")\n",
    "    cleaned_text = cleaned_text.replace(\"\\xa0\", \" \")\n",
    "    return cleaned_text\n",
    "\n",
    "df[\"description\"] = df[\"description\"].apply(clean_html)\n",
    "df[\"organization.description\"] = df[\"organization.description\"].apply(clean_html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"WTT_offers.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
